---
layout: cn_post
title: 大数据的陷阱3 高性能
categories: [互联网]
tags: [大数据]
---

最近一些人都在谈spark等平台，说比hadoop等快了1-2个数量级，因为是in-memory。可惜是scala语言实现，
虽然也有python接口。不知道除了这些大公司外，中小公司时候会心动呢。4年前我开始研究hadoop，但是2年前才真正使用，
而且用的不多。1年前果断适用graphlab，当然是应用所需了。但现在一些中小公司招人都在谈hadoop了，是不是这2年又要谈
spark呢。

spark是好用，但谁知道不会有一些更好的工具在未来3-5年出现呢。大家总是跟着工具跑，如果只是一些简单易用的工具到还好，
不好用可以及时换一个。如果是hadoop这样的庞大框架，切换的话对公司和RD的成本还是挺高的。就像web时代的产物ssh一样，
现在还有多少公司愿意用呢，那些投资呢？

我们更需要的是时代不变性的一些基本原理和工具原型，而不是庞大复杂解决一时问题的框架，不要被框架捆绑。

关键在系统，数据，模型，算法。

优化

硬件性能工具
大内存，多core，ssd，gpu

软性能工具
tcmalloc内存分配，llvm编译器

数据切分，磁盘寻道，内存分配，网络通信，高效结构。。。

数据并行，算法并行的思想，分布式解决的问题是什么，带来的更多复杂性。

